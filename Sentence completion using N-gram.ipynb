{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMadtEulhH3Tr5XFE+dYcw2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shamshad-Gilani/NLP-Projects/blob/main/Sentence%20completion%20using%20N-gram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk import bigrams\n",
        "from collections import Counter, defaultdict\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0F5F_ELSw3e",
        "outputId": "a9c73458-b594-4ce2-eebc-1950639d4189"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rxFaGLLSAhn",
        "outputId": "13c93f8e-773b-419b-c7b0-756c8d48023c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 recommendations: ['to', 'for', 'in']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Step 1: Download and extract the zip file\n",
        "url = 'https://www.kaggle.com/api/v1/datasets/download/unitednations/un-general-debates'\n",
        "response = requests.get(url)\n",
        "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
        "zip_file.extractall('archive')\n",
        "\n",
        "# Step 2: Load the CSV file\n",
        "csv_file = 'archive/un-general-debates.csv'\n",
        "data = pd.read_csv(csv_file)\n",
        "\n",
        "# Step 3: Preprocess the data\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    return tokens\n",
        "\n",
        "# Combine all text data into a single corpus\n",
        "corpus = ' '.join(data['text'].tolist())\n",
        "\n",
        "# Preprocess the corpus\n",
        "tokens = preprocess(corpus)\n",
        "\n",
        "# Step 4: Build the bigram model\n",
        "bigram_model = defaultdict(Counter)\n",
        "for w1, w2 in bigrams(tokens):\n",
        "    bigram_model[w1][w2] += 1\n",
        "\n",
        "# Function to recommend the top 3 words\n",
        "def recommend_next_words(word, bigram_model, top_n=3):\n",
        "    return bigram_model[word].most_common(top_n)\n",
        "\n",
        "# Test sentence\n",
        "test_sentence = \"it is a pleasure\"\n",
        "last_word = test_sentence.split()[-1]\n",
        "\n",
        "# Get recommendations\n",
        "recommendations = recommend_next_words(last_word, bigram_model)\n",
        "print(\"Top 3 recommendations:\", [word for word, count in recommendations])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk import bigrams\n",
        "from collections import Counter, defaultdict\n",
        "import string\n",
        "\n",
        "\n",
        "# Step 1: Download and extract the zip file\n",
        "url = 'https://www.kaggle.com/api/v1/datasets/download/unitednations/un-general-debates'\n",
        "response = requests.get(url)\n",
        "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
        "zip_file.extractall('archive')\n",
        "\n",
        "# Step 2: Load the CSV file\n",
        "csv_file = 'archive/un-general-debates.csv'\n",
        "data = pd.read_csv(csv_file)\n",
        "\n",
        "# Step 3: Preprocess the data\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    return tokens\n",
        "\n",
        "# Combine all text data into a single corpus\n",
        "corpus = ' '.join(data['text'].tolist())\n",
        "\n",
        "# Preprocess the corpus\n",
        "tokens = preprocess(corpus)\n",
        "\n",
        "# Step 4: Build the bigram model\n",
        "bigram_model = defaultdict(Counter)\n",
        "for w1, w2 in bigrams(tokens):\n",
        "    bigram_model[w1][w2] += 1\n",
        "\n",
        "# Function to recommend the next word\n",
        "def recommend_next_word(word, bigram_model):\n",
        "    return bigram_model[word].most_common(1)[0][0]\n",
        "\n",
        "# Test sentence\n",
        "test_sentence = \"it is a pleasure\"\n",
        "last_word = test_sentence.split()[-1]\n",
        "\n",
        "# Generate the next three words\n",
        "first_word = recommend_next_word(last_word, bigram_model)\n",
        "second_word = recommend_next_word(first_word, bigram_model)\n",
        "third_word = recommend_next_word(second_word, bigram_model)\n",
        "\n",
        "# Print the complete sentence\n",
        "complete_sentence = f\"{test_sentence} {first_word} {second_word} {third_word}\"\n",
        "print(\"Complete sentence:\", complete_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeDuCZk6WNIU",
        "outputId": "6871c05c-047c-435b-b0d7-07a9239d0c57"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete sentence: it is a pleasure to the united\n"
          ]
        }
      ]
    }
  ]
}